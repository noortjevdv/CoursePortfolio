---
title: "portfolio"
author: "Noortje van der Veen"
date: "2/23/2022"
output: 
  flexdashboard::flex_dashboard:
    orientation: columns
    storyboard: true
    theme: "cerulean"
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```
```{r}
library(flexdashboard)
library(plotly)
library(ggplot2)
library(tidyverse)
library(spotifyr)
library(compmus)
library(hexbin)
library(shiny)
library(ggpubr)
library(tidymodels)
library(ggdendro)
library(heatmaply)

```

```{r, echo=FALSE}
id <- "81f3df676d604409abfe7d3452016983"
secret <- "4dad5e4ae74e48849e41af9b3bc941c2"
Sys.setenv(SPOTIFY_CLIENT_ID = id)
Sys.setenv(SPOTIFY_CLIENT_SECRET = secret)
```


```{r}
JTNV2020 <- get_playlist_audio_features("", "37i9dQZF1ELZEbCiN09pZG?si=eace51fcd9ac4855")
```

```{r}
JTNV2021 <- get_playlist_audio_features("", "4uti3gC6MRxJFVu3P6Zq09?si=780acfc809e64cb1")
```

```{r}

topnummers <- bind_rows(
  JTNV2020 %>% mutate(category = "JTNV2020"),
  JTNV2021 %>% mutate(category = "JTNV2021")
)

```


Introduction and datasets
===============================

Column{.tabset .tabset-fade}
---------------------------------------

### Introduction

For my corpus, I will use two of the playlists that spotify made for me. 
The first playlist is **“Jouw topnummers van 2020”** and the second playlist is **“Jouw topnummers van 2021”**. What I find interesting about these playlists is that they are in some way representative of the music that I listened to in 2020 and 2021. I’m interested in seeing if there are specific things that have changed when it comes to my music taste. I think the tracks in these playlists are quite representative when it comes to the music that I listened to during those periods of time.

When comparing two tracks, it seemed most logical to me to compare the number one songs from both years. 
For 2020 that song is : **Why Why Why Why Why - Sault**
For 2021 that song is: **I know you, I live you - Chaka Khan**

Some features that I will look into include valence, energy, tempo, key and mode. 
I am not sure what my general preference is when it comes to these features, so I am interested to see if there are some things that stand out. 

On the side, you can see a little bit of the tables that contain the information about my toptracks from 2020 and 2021. The full table consists of 100 tracks per playlist, with 60 columns containing information about these tracks. 

***
The 2020 playlist will be represented by the color **red** in some of the graphs, while the 2021 playlist will be represented by the color **blue**. 

### Typical and Atypical tracks

**Some typical tracks from the 2020 playlist:**

Why Why Why Why Why - Sault

Colors - Black Pumas

Exit music (for a film) - Radiohead

Blue World - Mac Miller

H.f.g.w (Canyons Drunken Rage) - Tame Impala


**Some atypical tracks from the 2020 playlist**:

Fam - sor

Daisy - Ashnikko

Fragments of stasimon of Orestes by Euripides - Petros Tabouris


**Some typical tracks from the 2021 playlist**:

I know you, I live you - Chaka Khan

You Don’t Listen - General Elektriks

Famous - The Internet

Blackstar - David Bowie

Exit music (for a film) - Radiohead


**Some atypical tracks from the 2021 playlist**:

Temporary - Lauren Jauregui

SHUM - Go_A

Symphony No.5: IV. Adagietto. Sehr Langsam - Gustav Mahler


Column {.tabset .tabset-fade}
-----------------------------

#### Table 2020

```{r}
knitr::kable(JTNV2020[1:10,8:13], "pipe" )
```


#### Table 2021

```{r}
knitr::kable(JTNV2021[1:10,8:13], "pipe" )
```












Energy{data-navmenu="Tempo and Rhythm Related Features"}
===================================

Column{data-width=400}
-----------------------------------

### Summary


***
2020:
```{r, echo=FALSE}
summary(JTNV2020$energy)
```

***
2021:
```{r, echo=FALSE}
summary(JTNV2021$energy)
```

***
In the histogram, you can see the energy count per playlist. The included summary shows that both the median and the mean are not too far apart when you compare the 2020 and 2021 playlists. There is however, some difference when you look at the minimum and maximum energy. In my opinion this would mean that in 2021 I listened to a wider variety of music when it comes to energy.

The second chart shows that the 2020 playlist has a wider density. This could be explained by the minimum and maximum being less far apart, which makes the density wider. 



Column{data-width=600}
-----------------------------------

### Energy Count {data-padding=10}

```{r}
tophisto = topnummers %>%
  ggplot(aes(x = energy, fill = playlist_name)) + geom_histogram(binwidth = 0.1) +
  facet_wrap(~category) + 
  scale_fill_manual(values = c("light blue", "tomato"))

ggplotly(tophisto)
```


### Energy per year 2
```{r}
topviolin = topnummers %>%
  ggplot(aes(x = category, y = energy , col = playlist_name)) +
  geom_violin() + scale_color_manual(values = c("light blue", "tomato"))

ggplotly(topviolin)

```


Energy-Valence{data-navmenu="Tempo and Rhythm Related Features"}
====================
  
Column{data-width=300}
------------------
  
***
Correlation 2020 - Energy / Valence
```{r}
cor(JTNV2020$energy, JTNV2020$valence)
```

***
Correlation 2021 - Energy / Valence
```{r}
cor(JTNV2021$energy, JTNV2021$valence)
```

***
Energy valence 

The first graph shows the relation between **energy and valence** for both 2020 and 2021. I also calculated the correlation between these two variables. That calculation suggests that there is **more correlation between energy and valence in the 2020 playlist** than in the 2021 playlist. This is visually confirmed by the second chart, which in addition to energy and valence, also shows minor and major. The values seem to be more scattered in the 2021 graph.

Something I found interesting about this graph is that in the 2020 chart, minor songs generally score higher than major songs when it comes to energy. Something I think could explain this is that the top ten songs with the highest energy are all (hard)rock songs. These songs are often quite high in energy, even when they are in a minor key.

Another thing I found interesting about this graph is that the song with both the least energy and valence in the 2021 chart, is actually a song that does not really belong in the playlist. Last year I took a Musicological History course, for which we had to take a listening test, to prove that we were able to recognize a song by hearing it. One of the songs that I struggled with while studying was Symphony No. 5: IV. Adagietto. Sehr langsam by Gustav Mahler. This is the song with the lowest energy and valence. This means that it is not really a representative song, since I didn’t listen to it because I wanted to, but because I had to.


Column{data-width=700, .tabset .tabset-fade}
----------------
  
### Energy Valence {data-padding=10}
  
```{r}
topsmooth = topnummers %>% 
  ggplot(aes(x = valence, y = energy, fill = playlist_name)) + geom_point() + geom_smooth() + 
  facet_wrap(~playlist_name, dir = "v") +
  scale_fill_manual(values = c("light blue", "tomato"))

ggplotly(topsmooth)
```


### Energy Valence Mode 
```{r, echo=FALSE}

energy_valence = topnummers %>% 
  mutate(
    mode = ifelse(mode == 0, "Minor", "Major")
  ) %>%
  ggplot( 
    aes(
      x = valence,
      y = energy,
      size = loudness,
      colour = mode
    )
  ) +
  geom_point() +             
  geom_rug(size = 0.1) +     
  geom_text(                 
    aes(
      x = valence,
      y = energy,
      label = label
    ),
    data = 
      tibble(
        label = c(".", "."),
        category = c("JTNV2020", "JTNV2021"),
        valence = c(0.0605, 0.9600),
        energy = c(0.101, 0.967)
      ),
    colour = "black",         
    size = 3,                
    hjust = "left",          
    vjust = "bottom",     
    nudge_x = -0.05,        
    nudge_y = 0.02      
  ) +
  facet_wrap(~category) +     
  scale_x_continuous(      
    limits = c(0, 1),
    breaks = c(0, 0.50, 1),  
    minor_breaks = NULL      
  ) +
  scale_y_continuous(        
    limits = c(0, 1),
    breaks = c(0, 0.50, 1),
    minor_breaks = NULL
  ) +
  scale_colour_brewer(       
    type = "qual",          
    palette = "Paired"      
  ) +
  scale_size_continuous(     
    trans = "exp",           
    guide = "none"          
  ) +
  theme_light() +           
  labs(                  
    x = "Valence",
    y = "Energy",
    colour = "Mode"
  )

ggplotly(energy_valence)

```


### Valence Boxplot

```{r}
valenceplot = topnummers %>% 
  ggplot(aes(x = playlist_name, y = valence, fill = playlist_name)) +
  geom_boxplot() +
  scale_fill_manual(values = c("light blue", "tomato")) 

ggplotly(valenceplot)
```






Danceability{data-navmenu="Tempo and Rhythm Related Features"}
===================

Column 1{data-width=200}
-----------------
### Danceability
***
Danceability says something about how suitable a track is for dancing. 
This is based on multiple musical elements. Some of those elements are energy, tempo, rhythm stability and beat strength. 
The 2020 playlist has a higher median and a higher mean when it comes to the danceability variable. 
What I find interesting about this is that the 2021 playlist had a **higher mean energy**. 
There was barely any difference between the two playlists when it comes to the average tempo, with the 2021 playlist scoring 1.5 BPM higher on the average tempo. 
When I look at the top ten songs with the highest danceability for both playlists, I don’t see any differences that would give a logical explanation as to why the 2020 playlist has a higher mean danceability. 
When I look at the top ten songs with the **lowest danceability**, it makes more sense that the 2021 playlist scored lower. There are two songs from a **classical music** playlist that I had to listen to for a school assignment. Besides that I listened to more **rock songs** in 2021, and a few of those songs apparently score really low on danceability. 


Column 2{data-width=300, data-padding=20, .tabset .tabset-fade}
-----------

### Summary 

***
2020
```{r}
summary(JTNV2020$danceability)
```

***
2021
```{r}
summary(JTNV2021$danceability)
```


### Lowest Danceability
***
2020
```{r}
subJTNV2020 = subset(JTNV2020,select = c(danceability, track.name))

asc.dance.2020 = subJTNV2020 %>%
  arrange(danceability)

knitr::kable(asc.dance.2020[1:10,], "pipe" )
```

2021
```{r}
subJTNV2021 = subset(JTNV2021,select = c(danceability, track.name))

asc.dance.2021 = subJTNV2021 %>%
  arrange(danceability)

knitr::kable(asc.dance.2021[1:10,], "pipe" )
```



Column 3{data-width=500}
---------

### Distribution of Danceability Data. 

```{r}
viz4 <- ggplot(topnummers, aes(x=danceability, fill=playlist_name,
                            text = paste(playlist_name)))+
  geom_density(alpha=0.8, color=NA)+
  scale_fill_manual(values=c("dark blue", "tomato"))+
  labs(x="Danceability", y="Density") +
  guides(fill=guide_legend(title="Playlist"))+
  theme_minimal()+
  ggtitle("Distribution of Danceability Data")

ggplotly(viz4, tooltip=c("text"))
```








Tempo features{data-navmenu="Tempo and Rhythm Related Features"}
===============

Column{data-width=400}
--------------

***
An observation that I made is that the song with the highest tempo, can actually be viewed in halftime. It's the song parachutes by Jordan Mackampa. The song is in my opinion in halftime so that would mean that it is not a 193 BPM but 97 BPM. 

The tempo is the highest for songs with a 4/4 time signature. 

Even though the 2021 playlist has less outliers, it has a wider range when it comes to the lower and the upper fence. This can be seen in the boxplot. 

When at the songs that fall above the upper fence for the 2020 playlist, I can see that they have all been synced to a wrong tempo octave. Non of the top 5 highest tempo songs from that playlist actually have a higher tempo than 158 BPM, the upper fence. 

***
2020
```{r}
JTNV2020 %>%
  summarize(minTempo = min(tempo), meanTempo = mean(tempo), maxTempo = max(tempo))
```

***
2021
```{r}
JTNV2021 %>%
  summarize(minTempo = min(tempo), meanTempo = mean(tempo), maxTempo = max(tempo))
```



SD Tempo {.tabset .tabset-fade}
---------
### Tempo Boxplot

```{r}
"tempoi" = topnummers %>% 
  ggplot(aes(x = playlist_name, y = tempo, fill = playlist_name)) +
  geom_boxplot() +
  scale_fill_manual(values = c("light blue", "tomato"))

ggplotly(tempoi)
```

### SD Tempo

```{r}
nv2020 <-
  get_playlist_audio_features(
    "",
    "37i9dQZF1ELZEbCiN09pZG?si=d5fbdd58fd4146e3"
  ) %>%
  slice(1:30) %>%
  add_audio_analysis()
nv2021 <-
  get_playlist_audio_features(
    "",
    "4uti3gC6MRxJFVu3P6Zq09?si=9cfd7d2717d24ede"
  ) %>%
  slice(1:30) %>%
  add_audio_analysis()
beide <-
  nv2020 %>%
  mutate(year = "2020") %>%
  bind_rows(nv2021 %>% mutate(year = "2021"))

beide %>%
  mutate(
    sections =
      map(
        sections,                                    # sections or segments
        summarise_at,
        vars(tempo, loudness, duration),             # features of interest
        list(section_mean = mean, section_sd = sd)   # aggregation functions
      )
  ) %>%
  unnest(sections) %>%
  ggplot(
    aes(
      x = tempo,
      y = tempo_section_sd,
      colour = year,
      alpha = loudness
    )
  ) +
  geom_point(aes(size = duration / 60)) +
  geom_rug() +
  theme_minimal() +
  ylim(0, 5) +
  labs(
    x = "Mean Tempo (bpm)",
    y = "SD Tempo",
    colour = "Year",
    size = "Duration (min)",
    alpha = "Volume (dBFS)"
  )
```

### time signature - tempo -mode

```{r}
timesigtempo = ggplot(topnummers, aes(x = time_signature, y = tempo, color = as.factor(mode))) +
  geom_point(alpha = 0.5) + labs(title = "Time signature, tempo and mode",
                       x = "Time Signature",
                       y = "Tempo",
                       color = "Mode") +
  
  facet_wrap(~playlist_name) +
  scale_color_manual(values = c("pink", "coral")) +  
  scale_color_discrete(labels = c("minor", "major"))

ggplotly(timesigtempo)
```




Tempograms{data-navmenu="Tempo and Rhythm Related Features"}
=============

Text{data-width=300}
---------
Both of the tempograms show issues with correctly identifying the songs in the right tempo octave. 
The 2021 tempogram is even more flawed than the 2020 tempogram, since it barely shows any difference between 113 bpm and the other tempo's.


***
```{r}
subtop2020 = subset(JTNV2020,select = c(playlist_name, track.name, tempo)) 

knitr::kable(subtop2020[1,], "pipe" )
```


```{r}
subtop2021 = subset(JTNV2021,select = c(playlist_name, track.name, tempo))

knitr::kable(subtop2021[1,], "pipe" )
```



Tempograms{.tabset .tabset-fade}
------------

### 2020

```{r}
wx5 <- get_tidy_audio_analysis("4zwq3QUKgMNk0NSLl7fpbP?si=adbccc789d3a4d76")

wx5 %>% tempogram(window_size = 8, hop_size = 1, cyclic = FALSE) %>%
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()

```


### 2021

```{r}
ikyily2 <-get_tidy_audio_analysis("0W8MpnhaImy0oPRkVpRvjI?si=8da5d812dfad4637")

ikyily2 %>%
  tempogram(window_size = 8, hop_size = 1, cyclic = FALSE) %>%
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()
```




Keys and chords{data-navmenu="Harmonic Music Features"}
==============

Column{data-width=250}
----------
***
The most used key in 2021 is C#-major. The most used key in 2020 is A-minor. 
The 2021 playlist contains 53 songs in a **major** key, and 47 in a minor key. 
The 2020 playlist contains 56 songs in a **minor** key and 44 in a major key.  
This can be linked to the mean valence, energy and tempo for both playlists as well. Those three features are all higher for the 2021 playlist. 
From this the conclusion can be drawn that the 2021 playlist was a bit ‘happier’ than the 2020 playlist. 

***
Mean Valence 2020
```{r}
mean(JTNV2020$valence)
```
Mean Valence 2021
```{r}
mean(JTNV2021$valence)
```



Column {.tabset .tabset-fade}
---------------------

### Key name histogram

```{r}
keynamehist = topnummers %>% 
  ggplot(aes(x = key_name, fill = playlist_name)) + geom_bar(width = 0.5) + facet_wrap(~ playlist_name) +
  scale_fill_manual(values = c("light blue", "tomato"))

ggplotly(keynamehist)
```

### Key minor major

```{r}
keymode = topnummers %>% 
  ggplot(aes(x = key_mode, fill = playlist_name)) + geom_bar(width = 0.5) + facet_wrap(~ playlist_name) + scale_x_discrete(guide = guide_axis(angle = -90)) +
  scale_fill_manual(values = c("light blue", "tomato"))

keymode
```

### Mode
```{r}
majmincount = ggplot(topnummers, aes(x=mode, fill = playlist_name)) + geom_histogram() + facet_wrap(~playlist_name) + labs(x = "mode: 0 = minor, 1 = major") +
  scale_fill_manual(values = c("light blue", "tomato"))

ggplotly(majmincount)
```


Loudness{data-navmenu="Harmonic Music Features" data-orientation=rows}
==========

Graphs
------------

### Boxplot
```{r}
loudie = topnummers %>% 
  ggplot(aes(x = playlist_name, y = loudness, fill = playlist_name)) +
  geom_boxplot() +
  scale_fill_manual(values = c("light blue", "tomato")) 

ggplotly(loudie)
```


### Table Lowest Loudness 2020


```{r}
subloudJTNV2020 = subset(JTNV2020,select = c(loudness, track.name))

asc.loud.2020 = subloudJTNV2020 %>%
  arrange(loudness)

knitr::kable(asc.loud.2020[1:10,], "pipe" )
```

### Table Lowest Loudness 2021

```{r}
subloudJTNV2021 = subset(JTNV2021,select = c(loudness, track.name))

asc.loud.2021 = subloudJTNV2021 %>%
  arrange(loudness)

knitr::kable(asc.loud.2021[1:10,], "pipe" )
```

Text{data-height=200}
------------
### Explaination
The means and medians for both playlists are quite similar. However, the 2021 shows a broader distribution of the quantiles. The 2021 playlist also shows more outliers. The outlier with -35dB is a classical piece that I had to listen to for school. 
Multiple of the outliers are classical music, which would explain why they may have a lower loudness value. 



### Mean
Mean Loudness 2020
```{r}
mean(JTNV2020$loudness)
```
Mean Loudness 2021
```{r}
mean(JTNV2021$loudness)
```



Speechiness and Acousticness{data-navmenu="Harmonic Music Features"}
============

Means{data-width=300}
----------

### Explaination
As you can see, the mean for acousticness is higher for the 2021 playlist and the mean for speechiness is higher for the 2020 playlist. The 'outlier' that can be seen in the histogram for the 2020 playlist is a rap song called D/Vision by JID. The fact that it is a rap song explains the high level of speechiness. Most of the songs with high acousticness are classical songs, of which some are from a classical playlist that I had to study for a school assignment.

Something that is interesting to me is that the 2021 playlist shows a negative correlation when it comes to acousticness and speechiness. 

Correlation 2020, 2021 - Acousticness, Speechiness
```{r}
cor(JTNV2020$acousticness, JTNV2020$speechiness)
```

```{r}
cor(JTNV2021$acousticness, JTNV2021$speechiness)
```


### Means
mean speechiness 2020
```{r}
mean(JTNV2020$speechiness)
```

mean speechiness 2021
```{r}
mean(JTNV2021$speechiness)
```

mean acousticness 2020
```{r}
mean(JTNV2020$acousticness)
```

mean acousticness 2021
```{r}
mean(JTNV2021$acousticness)
```


Graphs{data-width=700, .tabset .tabset-fade}
----------

### Histogram Speechiness

```{r}
speechihist = topnummers %>%
  ggplot(aes(x = speechiness, fill = playlist_name)) + geom_histogram() + facet_wrap(~playlist_name, dir = "v") + 
  scale_fill_manual(values = c("light blue", "tomato"))


ggplotly(speechihist)
```

### Histogram Acousticness

```{r}
acousthist = topnummers %>%
  ggplot(aes(x = acousticness, fill = playlist_name)) + geom_histogram() + facet_wrap(~playlist_name, dir = "v") +
  scale_fill_manual(values = c("light blue", "tomato"))


ggplotly(acousthist)
```


### Acousticness - Speechiness


```{r}
acsp = topnummers %>% 
  ggplot(aes(x = speechiness, y = acousticness, fill = playlist_name)) + geom_point(alpha = 0.85) + geom_smooth() + 
  facet_wrap(~playlist_name, dir = "v") +
  scale_fill_manual(values = c("light blue", "tomato"))


ggplotly(acsp)
```






Chroma Features{data-navmenu="Harmonic Music Features"}
==========================

Top song of 2020, SAULT - whywhywhywhywhy {.tabset}
---------------------------

### Top song of 2020, SAULT - whywhywhywhywhy, Pitch

```{r, echo=FALSE}

whywhywhy <-
  get_tidy_audio_analysis("4zwq3QUKgMNk0NSLl7fpbP?si=dcd0036a52154ea5") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

pitchw5 = whywhywhy %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()

ggplotly(pitchw5)


```

### Timbre

```{r}
w5 <-
  get_tidy_audio_analysis("4zwq3QUKgMNk0NSLl7fpbP?si=adbccc789d3a4d76") %>% 
  compmus_align(bars, segments) %>%                     # Change `bars`
  select(bars) %>%                                      #   in all three
  unnest(bars) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )




w5 %>%
  compmus_gather_timbre() %>%
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c() +                              
  theme_classic()
```



Top song of 2021, Chaka Khan - I know you, I live you {.tabset}
----------------

### Top song of 2021, Chaka Khan - I know you, I live you, Pitch

```{r}
chaka <-
  get_tidy_audio_analysis("0W8MpnhaImy0oPRkVpRvjI?si=a6fff186744843ec") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

pitchchaka = chaka %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()

ggplotly(pitchchaka)

```

### Timbre, 

```{r}
ikyily <-
  get_tidy_audio_analysis("0W8MpnhaImy0oPRkVpRvjI?si=8da5d812dfad4637") %>% 
  compmus_align(bars, segments) %>%                     # Change `bars`
  select(bars) %>%                                      #   in all three
  unnest(bars) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )



ikyily %>%
  compmus_gather_timbre() %>%
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c() +                              
  theme_classic()
```




Text{data-width=300}
----------
***
**Pitch**

**Why Why Why Why Why**
During the song, D is the most used pitch. Other common pitches are F and A. This could be explained by the fact that a D-Minor chord consists of D-F-A. 
Another pitch that seems to have a high magnitude is Db. 
An explanation could be that the song features the 7th tone often, but I think it is more likely that the 7th tone here is C, which is also shown to have a relatively high magnitude for some parts of the song. 
In my opinion it is more likely that the D was read by the algorithm as a Db. 

**I Know You, I Live You **
The pitches that have the highest magnitude are C, Db, D, G and A. According to the spotify analysis the key for this song is Gm. This would explain the high magnitude for the G and D pitch. The dominant key for Gm is Dm, which would explain the high magnitude for the A tone, since the D-minor chord consists of D-F-A. 


**Timbre**
It can be said that for both the 2020 and the 2021 song the lower coefficients capture more of the timbre information. 
‘Why Why Why Why Why’ shows a high magnitude for c01, c02 and c03. ‘I Know You, I Live You’ mainly shows a high magnitude for c02. 






Self Similarity{data-navmenu="Harmonic Music Features"}
================

Column{data-width=700, .tabset .tabset-fade}
---------

### Self similarity 2020

```{r}
SSW5 = w5 %>%
  compmus_self_similarity(timbre, "cosine") %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")

ggplotly(SSW5)

```

### Self similarity 2021

```{r}
SSIKY = ikyily %>%
  compmus_self_similarity(timbre, "cosine") %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")

ggplotly(SSIKY)
```


Explaination
-----------

The structure of the 2020 top track, 'Why Why Why Why Why', can be seen as an A-B-C-B-C-B structure.The parts of the song that are instrumental are often found at the beginning of a new letter, for example, the darker blue block at duration 0-16, the intro and 59-65. 
This is a song that features a lot a variation between the different verses and choruses. 
I think that explains why the matrix is not the cleanest. 

The structure of the 2021 top track, 'I Know You, I Live You' can be seen as an A-B-A-B-B structure. 





Clustering
==============

Text{data-width=300}
---------
***
Some songs that are linked in the **2020 dendrogram** include ‘She Can’t Love You’ and ‘Mad At Me’. These songs are both R&B songs. ‘Back Pocket’ and ‘Lockdown’ are both songs in which the baseline plays an important role. They also have a similar timbre coefficient. 
The top song for 2020, ‘Why Why Why Why Why’, is clustered with ‘Breeze’, which is the 18th song on that playlist. They have similar values for speechiness, timbre coefficient c02 and liveness. 

***
Some songs that are linked in the **2021 dendrogram** include ‘Krunk’ and ‘Little Lady’. These songs being linked surprised me, because they don’t sound very similar to me. When looking at the heat map, I can see that they are actually quite similar if you look at speechiness, loudness and key. These are some features that I don’t necessarily notice consciously when I listen to music, but that are clearly still important for clustering music. 
Another cluster that surprised me is ‘You Oughta Know’ and ‘Famous’, one being a rock song, while the other is R&B. They are similar when you look at the timbre features, having very similar values for multiple timbre coefficients. They also have similar values for instrumentalness and danceability. 


Heatmaps{.tabset .tabset-fade}
----------

```{r}
mark2020 <-
  get_playlist_audio_features("", "37i9dQZF1ELZEbCiN09pZG?si=d70969c7136a48f6") %>%
  add_audio_analysis() %>%
  mutate(
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  ) %>%
  mutate(pitches = map(pitches, compmus_normalise, "clr")) %>%
  mutate_at(vars(pitches, timbre), map, bind_rows) %>%
  unnest(cols = c(pitches, timbre))

mark2020_juice <-
  recipe(
    track.name ~
      danceability +
      energy +
      loudness +
      speechiness +
      acousticness +
      instrumentalness +
      liveness +
      valence +
      tempo +
      duration +
      C + `C#|Db` + D + `D#|Eb` +
      E + `F` + `F#|Gb` + G +
      `G#|Ab` + A + `A#|Bb` + B +
      c01 + c02 + c03 + c04 + c05 + c06 +
      c07 + c08 + c09 + c10 + c11 + c12,
    data = mark2020
  ) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors()) %>% 
  # step_range(all_predictors()) %>% 
  prep(mark2020 %>% mutate(track.name = str_trunc(track.name, 20))) %>%
  juice() %>%
  column_to_rownames("track.name")

goed2020.20 = mark2020_juice %>%
  slice(1:20)

jtnv2020mark_dist <- dist(goed2020.20, method = "euclidean")

```



```{r}
mark2021 <-
  get_playlist_audio_features("", "4uti3gC6MRxJFVu3P6Zq09?si=abc053435c0e4bc7") %>%
  add_audio_analysis() %>%
  mutate(
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  ) %>%
  mutate(pitches = map(pitches, compmus_normalise, "clr")) %>%
  mutate_at(vars(pitches, timbre), map, bind_rows) %>%
  unnest(cols = c(pitches, timbre))

mark2021_juice <-
  recipe(
    track.name ~
      danceability +
      energy +
      loudness +
      speechiness +
      acousticness +
      instrumentalness +
      liveness +
      valence +
      tempo +
      duration +
      C + `C#|Db` + D + `D#|Eb` +
      E + `F` + `F#|Gb` + G +
      `G#|Ab` + A + `A#|Bb` + B +
      c01 + c02 + c03 + c04 + c05 + c06 +
      c07 + c08 + c09 + c10 + c11 + c12,
    data = mark2021
  ) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors()) %>% 
  # step_range(all_predictors()) %>% 
  prep(mark2021 %>% mutate(track.name = str_trunc(track.name, 20))) %>%
  juice() %>%
  column_to_rownames("track.name")

goed2021.20 = mark2021_juice %>%
  slice(1:20)

jtnv2021mark_dist <- dist(goed2021.20, method = "euclidean")

```


### Heat map 2020

```{r}
goed2020.20 = mark2020_juice %>%
  slice(1:20)

heatmaply(
  goed2020.20,
  hclustfun = hclust,
  hclust_method = "average",  # Change for single, average, or complete linkage.
  dist_method = "euclidean"
)
```


### Heat map 2021

```{r}
goed2021.20 = mark2021_juice %>%
  slice(1:20)

heatmaply(
  goed2021.20,
  hclustfun = hclust,
  hclust_method = "average",  # Change for single, average, or complete linkage.
  dist_method = "euclidean"
)
```






Conclusion
===========

Some of the features that I analysed for this portfolio show high similarity between the 2020 playlist and the 2021 playlist. They gave similar energy histograms, both used 4/4 the most for time signature, and had almost the same tempo mean and median. Other features like mean acousticness and median loudness were almost the same for both playlists. 

There were also some features that were less similar. The 2021 playlist showed a broader width for the valence quantiles. The songs were also more scattered around the 2021 valence-energy-mode graph than in the 2020 graph. In other words, the 2020 playlist showed more correlation between energy and valence. 

Both of the top songs in these playlists showed a high magnitude for the pitched D and Db, which is interesting to me because D and Db were the number 2 and 3 most used keys for 2021, but they were way less used in 2020.  


And then there were the cases of features that didn't show a lot of similarity, but that were in my opinion influenced by songs that didn't belong in my top tracks. 
For instance, the danceability data was influenced by a couple of tracks that ended up in my top 100 because I had to study them for a school assignment. These same songs also influenced the loudness and speechiness features. 
There were also some problems with analysing the tempo features, since some of the outliers were in my opinion in the wrong tempo octave. 


